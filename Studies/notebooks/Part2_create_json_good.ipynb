{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/02\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../python\")\n",
    "import InputsProducer\n",
    "import ParametrizedModel as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InputsProducer import SampleType as st\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = '/data/dido/new_samples/NN_samples/GluGluToRadionToHHTo2B2Tau_M-*_*Tau_2016_*.root'\n",
    "# file = '/data/dido/samples_23_10/GluGluToHHTo2B2Tau_node_SM_tauTau_2018_ggHH_NonRes.root'\n",
    "# file = '/data/dido/samples_23_10/GluGluToHHTo2B2Tau_node_*2016*.root'\n",
    "file = '/data/dido/samples_23_10/*.root'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 40s, sys: 5.56 s, total: 6min 45s\n",
      "Wall time: 7min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = InputsProducer.CreateRootDF(file, 0, True, True)\n",
    "X, Y, Z, var_pos, var_pos_z, var_name = InputsProducer.CreateXY(data, '../config/training_variables.json' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('X_par0_v2', X)\n",
    "# np.count_nonzero(X - X_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params =  {\"activation_dense_post\": \"sigmoid\", \"activation_dense_pre\": \"sigmoid\", \"dropout_rate_den_layers_post\": 0, \n",
    "           \"dropout_rate_den_layers_pre\": 0, \"dropout_rate_rnn\": 0.0, \"learning_rate_exp\": -3.0,\n",
    "           \"num_den_layers_post\": 13, \"num_den_layers_pre\": 0, \"num_rnn_layers\": 5, \"num_units_den_layers_post\": 15, \n",
    "           \"num_units_den_layers_pre\": 1, \"num_units_rnn_layer\": 74, \"optimizers\": \"Adam\", \"rnn_type\": \"LSTM\", \n",
    "           \"batch_size\": 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pm.HHModel(var_pos, '../config/mean_std_red.json', '../config/min_max_red.json', params)\n",
    "model.call(X[0:1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              weighted_metrics=[pm.sel_acc_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(X.shape)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../python/training_17_04_2020_par1_best_weights.h5', by_name=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X, batch_size=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pred_par0_v2', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.sel_acc(Y, pred, 2, 2,True, True)#X[:,:,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016\n",
    "# VBF non res\n",
    "# VBFHHTo2B2Tau_CV_0_5_C2V_1_C3_1\n",
    "# VBFHHTo2B2Tau_CV_1_5_C2V_1_C3_1\n",
    "# VBFHHTo2B2Tau_CV_1_C2V_1_C3_0\n",
    "# VBFHHTo2B2Tau_CV_1_C2V_1_C3_1\n",
    "# VBFHHTo2B2Tau_CV_1_C2V_1_C3_2\n",
    "# VBFHHTo2B2Tau_CV_1_C2V_2_C3_1\n",
    "nodes_values_2016_vbf = [1,2,3,4,5,6]\n",
    "\n",
    "\n",
    "# ggF non res\n",
    "nodes_label_2016 = ['SM', 'box', '2','3','4','7','9','12']\n",
    "nodes_values_2016 = [0,1,2,9,10,11,12,13]\n",
    "\n",
    "# ggF res Graviton\n",
    "mass_points_graviton_2016 = [250, 260, 270,280,300,320,340,350,400,450,500,550,600,650,750,800]\n",
    "# ggF res Graviton\n",
    "mass_points_radion_2016 = [250, 260, 270,280,300,320,340,350,400,450,500,550,600,650,800, 900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017\n",
    "# VBF non res\n",
    "# VBFHHTo2B2Tau_CV_1_5_C2V_1_C3_1\n",
    "# VBFHHTo2B2Tau_CV_1_C2V_1_C3_0\n",
    "# VBFHHTo2B2Tau_CV_1_C2V_1_C3_1\n",
    "# VBFHHTo2B2Tau_CV_1_C2V_1_C3_2\n",
    "# VBFHHTo2B2Tau_CV_1_C2V_2_C3_1\n",
    "nodes_values_2017_vbf = [2,3,4,5,6]\n",
    "\n",
    "# ggF non res\n",
    "nodes_label_2017 = ['SM', 2,3,4,7,9,12]\n",
    "nodes_values_2017 = [0,2,3,4,7,9,12]\n",
    "\n",
    "# ggF res Graviton\n",
    "mass_points_graviton_2017 = [250,260,270,280,350,400,450,550,600,650,750,800]\n",
    "# ggF res Graviton\n",
    "mass_points_radion_2017 = [250,260,270,280,300,320,350,400,450,500,550,600,650,700,750,800,850,900,1000,1250,1500,1750,2000,2500,3000]\n",
    "\n",
    "# VBF res Graviton\n",
    "mass_points_graviton_vbf_2017 = [250,260,270,280,300,320,350,400,450,500,600,650,700,750,850,900,1000,1750,2000]\n",
    "# VBF res Graviton\n",
    "mass_points_radion_vbf_2017 = [250,270,280,300,350,400,450,500,550,600,650,700,750,800,850,900,1000,1250,1500,1750,2000,3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018\n",
    "# VBF non res\n",
    "# VBFHHTo2B2Tau_CV_0_5_C2V_1_C3_1\n",
    "# VBFHHTo2B2Tau_CV_1_5_C2V_1_C3_1\n",
    "# VBFHHTo2B2Tau_CV_1_C2V_1_C3_0\n",
    "# VBFHHTo2B2Tau_CV_1_C2V_1_C3_1\n",
    "# VBFHHTo2B2Tau_CV_1_C2V_1_C3_2\n",
    "# VBFHHTo2B2Tau_CV_1_C2V_2_C3_1\n",
    "\n",
    "nodes_values_2018_vbf = [1,2,3,4,5,6]\n",
    "\n",
    "\n",
    "# ggF non res\n",
    "nodes_label_2018 = ['SM',2,3,4,5,6,7,8,9,10,11,12]\n",
    "nodes_values_2018 = [0,2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "# ggF res Graviton\n",
    "mass_points_graviton_2018 = [250,260,270,280,300,320,350,400,450,500,550,600,650,700,750,800,850,900,1000,1250,1500,1750,2000,2500,3000]\n",
    "# ggF res Radion\n",
    "mass_points_radion_2018 = [250,260,270,280,300,320,350,400,450,500,550,600,650,700,750,800,850,900,1000,1250,1500,1750,2000,2500,3000]\n",
    "\n",
    "# VBF res Graviton\n",
    "mass_points_graviton_vbf_2018 = [250,260,270,280,300,320,350,400,450,500,600,650,700,750,850,900,1000,1200,1750,2000]\n",
    "# VBF res Graviton\n",
    "mass_points_radion_vbf_2018 = [250,260,270,280,300,320,350,400,450,500,550,600,650,700,750,800,900,1000,1250,1500,1750,2000,3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_acc(y_true, y_pred, n_positions, n_exp):\n",
    "    pred_sorted = tf.argsort(y_pred, axis=1, direction='DESCENDING')\n",
    "    n_evt = tf.shape(y_true)[0]\n",
    "    evt_id = tf.range(n_evt)\n",
    "    matches_vec = []\n",
    "    for n in range(n_positions):\n",
    "        index = tf.transpose(tf.stack([evt_id, tf.reshape(pred_sorted[:, n], shape=(n_evt,))]))\n",
    "        matches_vec.append(tf.gather_nd(y_true, index))\n",
    "    matches_sum = tf.add_n(matches_vec)\n",
    "    valid = tf.cast(tf.equal(matches_sum, n_exp), tf.float32)\n",
    "    n_valid = tf.reduce_sum(valid)\n",
    "    return n_valid / tf.cast(n_evt, tf.float32), n_valid, tf.cast(n_evt, tf.float32)\n",
    "\n",
    "def sel_acc_2(y_true, y_pred):\n",
    "    return sel_acc(y_true, y_pred, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_prod(point, sample_type, spin, year, discr, channel, new_method, deep_csv, res):\n",
    "    index = []\n",
    "    for node in range(0, len(point)) :\n",
    "        if res == True :\n",
    "            index.append((Z[:, 0, 0] == sample_type) & (Z[:, 0, 1] == spin) & (Z[:, 0, 2] == point[node]) & (Z[:, 0, 4] == year) & (Z[:, 0, 5] == channel))\n",
    "        if res == False :\n",
    "            index.append((Z[:, 0, 0] == sample_type) & (Z[:, 0, 3] == point[node]) & (Z[:, 0, 4] == year) & (Z[:, 0, 5] == channel))\n",
    "    acc = []\n",
    "    valid = []\n",
    "    n_evt_sample = []\n",
    "    for idx in range(0, len(index)):\n",
    "#         print(Y[index[idx], : , 0])\n",
    "#         pred = Y[index[idx], : , 0]\n",
    "        pred = Y[index[idx], : , 0]\n",
    "\n",
    "        if new_method == True : \n",
    "            y_pred = predictions[index[idx]]\n",
    "        elif new_method == False and deep_csv == False:\n",
    "            y_pred = X[index[idx], : , discr]\n",
    "        elif new_method == False and deep_csv == True:\n",
    "            y_pred = data[index[idx], : , -1]\n",
    "            \n",
    "        ratio, n_valid, n_evt = sel_acc_2(pred, y_pred)\n",
    "        x = ratio.numpy()\n",
    "        acc.append(float(x))\n",
    "        valid.append(float(n_valid))\n",
    "        n_evt_sample.append(float(n_evt))\n",
    "    return acc, valid, n_evt_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitializeDict(x, x_labels, sample_type, spin, year, discr , channel, res, fig_name, x_axis_label,sample_title, log_xscale, name_tag):\n",
    "    \n",
    "    acc, valid, n_valid_sample = acc_prod(x, sample_type, spin, year, discr, channel, True, False, res)\n",
    "    acc_df, valid_df, n_valid_sample_df = acc_prod(x, sample_type, spin, year, discr, channel, False, False, res)\n",
    "    acc_deepcsv, valid_deepcvs, n_valid_sample_deepcsv = acc_prod(x, sample_type, spin, year, discr, channel, False, True, res)\n",
    "    \n",
    "    \n",
    "    score_info[name_tag] = {\"HH-btag\": {\"acc\": acc , \"valid\": valid, \"n_evt_sample\": n_valid_sample}, \n",
    "                            \"DF\":      {\"acc\":acc_df , \"valid\": valid_df, \"n_evt_sample\": n_valid_sample_df}, \n",
    "                            \"DeepCSV\": {\"acc\":acc_deepcsv , \"valid\": valid_deepcvs, \"n_evt_sample\": n_valid_sample_deepcsv}\n",
    "    }   \n",
    "    return score_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# args = x, x_labels, sample_type, spin, year, discr , channel, res, fig_name, x_axis_label,sample_title,pdf, log_xscale, name_tag):\n",
    "channel_name = ['ETau', 'MuTau', 'TauTau']\n",
    "for channel in range(len(channel_name)):\n",
    "    #2016\n",
    "    InitializeDict(nodes_values_2016, nodes_values_2016, st.ggHH_NonRes, 0, 2016, 6, channel, False, 'plots/2016/non_res{}.pdf'.format(channel_name[channel]), 'node', 'Non Res ggF {}'.format(channel_name[channel]), False, 'ggHH_NonRes_{}_2016'.format(channel))\n",
    "    InitializeDict(nodes_values_2016_vbf, nodes_values_2016_vbf, st.VBFHH_NonRes, 0, 2016, 6, channel, False, 'plots/2016/non_res_vbf_{}.pdf'.format(channel_name[channel]), 'node', 'Non Res VBF {}'.format(channel_name[channel]), False, 'VBFHH_NonRes{}_2016'.format(channel))\n",
    "    InitializeDict(mass_points_graviton_2016, mass_points_graviton_2016, st.ggHH_Res, 2, 2016, 6, channel, True, 'plots/2016/graviton_{}.pdf'.format(channel_name[channel]), 'mass [GeV]', 'Graviton {}'.format(channel_name[channel]), True, 'ggHH_Res_R_{}_2016'.format(channel))\n",
    "    InitializeDict(mass_points_radion_2016, mass_points_radion_2016, st.ggHH_Res, 0, 2016, 6, channel, True, 'plots/2016/radion_{}.pdf'.format(channel_name[channel]), 'mass [GeV]', 'Radion {}'.format(channel_name[channel]), True, 'ggHH_Res_G_{}_2016'.format(channel))\n",
    "    #2017\n",
    "    InitializeDict(nodes_values_2017, nodes_values_2017, st.ggHH_NonRes, 0, 2017, 6, channel, False, 'plots/2017/non_res{}.pdf'.format(channel_name[channel]), 'node', 'Non Res ggF {}'.format(channel_name[channel]), False, 'ggHH_NonRes_{}_2017'.format(channel))\n",
    "    InitializeDict(nodes_values_2017_vbf, nodes_values_2017_vbf, st.VBFHH_NonRes, 0, 2017, 6, channel, False, 'plots/2017/non_res_vbf_{}.pdf'.format(channel_name[channel]), 'node', 'Non Res VBF {}'.format(channel_name[channel]), False, 'VBFHH_NonRes_{}_2017'.format(channel))\n",
    "    InitializeDict(mass_points_graviton_2017, mass_points_graviton_2017, st.ggHH_Res, 2, 2017, 6, channel, True, 'plots/2017/graviton_{}.pdf'.format(channel_name[channel]), 'mass [GeV]', 'Graviton {}'.format(channel_name[channel]), True, 'ggHH_Res_R_{}_2017'.format(channel))\n",
    "    InitializeDict(mass_points_radion_2017, mass_points_radion_2017, st.ggHH_Res, 0, 2017, 6, channel, True, 'plots/2017/radion_{}.pdf'.format(channel_name[channel]), 'mass [GeV]', 'Radion {}'.format(channel_name[channel]), True, 'ggHH_Res_G_{}_2017'.format(channel))\n",
    "    InitializeDict(mass_points_graviton_vbf_2017, mass_points_graviton_vbf_2017, st.VBFHH_Res, 2, 2017, 6, channel, True, 'plots/2017/VBF_graviton_{}.pdf'.format(channel_name[channel]), 'mass [GeV]', 'VBF Graviton {}'.format(channel_name[channel]), False, 'VBFHH_Res_R_{}_2017'.format(channel))\n",
    "    InitializeDict(mass_points_radion_vbf_2017, mass_points_radion_vbf_2017, st.VBFHH_Res, 0, 2017, 6, channel, True, 'plots/2017/VBF_radion_{}.pdf'.format(channel_name[channel]), 'mass [GeV]', 'VBF Radion {}'.format(channel_name[channel]), False, 'VBFHH_Res_G_{}_2017'.format(channel))\n",
    "    #2018\n",
    "    InitializeDict(nodes_values_2018, nodes_values_2018, st.ggHH_NonRes, 0, 2018, 6, channel, False, 'plots/2018/non_res{}.pdf'.format(channel_name[channel]), 'node', 'Non Res ggF {}'.format(channel_name[channel]), False, 'ggHH_NonRes_{}_2018'.format(channel))\n",
    "    InitializeDict(nodes_values_2018_vbf, nodes_values_2018_vbf, st.VBFHH_NonRes, 0, 2018, 6, channel, False, 'plots/2018/non_res_vbf_{}.pdf'.format(channel_name[channel]), 'node', 'Non Res VBF {}'.format(channel_name[channel]), False, 'VBFHH_NonRes_{}_2018'.format(channel))\n",
    "    InitializeDict(mass_points_graviton_2018, mass_points_graviton_2018, st.ggHH_Res, 2, 2018, 6, channel, True, 'plots/2018/graviton_{}.pdf'.format(channel_name[channel]), 'mass [GeV]', 'Graviton {}'.format(channel_name[channel]), True, 'ggHH_Res_R_{}_2018'.format(channel))\n",
    "    InitializeDict(mass_points_radion_2018, mass_points_radion_2018, st.ggHH_Res, 0, 2018, 6, channel, True, 'plots/2018/radion_{}.pdf'.format(channel_name[channel]), 'mass [GeV]', 'Radion {}'.format(channel_name[channel]), True, 'ggHH_Res_G_{}_2018'.format(channel))\n",
    "    InitializeDict(mass_points_graviton_vbf_2018, mass_points_graviton_vbf_2018, st.VBFHH_Res, 2, 2018, 6, channel, True, 'plots/2018/VBF_graviton_{}.pdf'.format(channel_name[channel]), 'mass [GeV]', 'VBF Graviton {}'.format(channel_name[channel]), False, 'VBFHH_Res_R_{}_2018'.format(channel))\n",
    "    InitializeDict(mass_points_radion_vbf_2018, mass_points_radion_vbf_2018, st.VBFHH_Res, 0, 2018, 6, channel, True, 'plots/2018/VBF_radion_{}.pdf'.format(channel_name[channel]), 'mass [GeV]', 'VBF Radion {}'.format(channel_name[channel]), False, 'VBFHH_Res_G_{}_2018'.format(channel))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
