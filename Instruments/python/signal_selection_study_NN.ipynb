{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/02\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Bidirectional, Masking, TimeDistributed, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Convolution2D, MaxPooling2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT.gInterpreter.Declare('''\n",
    "using LorentzVectorM = ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<float> >;\n",
    "using LorentzVectorE = ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiE4D<float> >;\n",
    "using LorentzVector = ROOT::Math::LorentzVector<ROOT::Math::PxPyPzE4D<float> >;\n",
    "\n",
    "ROOT::VecOps::RVec<LorentzVectorE> jets_p4_good(const ROOT::VecOps::RVec<LorentzVectorE>& jets_p4)\n",
    "{\n",
    "    ROOT::VecOps::RVec<LorentzVectorE> selected_jets;\n",
    "    for(size_t jet_index = 0; jet_index < jets_p4.size(); ++jet_index){\n",
    "        if(jets_p4.at(jet_index).pt() > 20 && abs(jets_p4.at(jet_index).eta()) < 2.4)\n",
    "            selected_jets.push_back(jets_p4.at(jet_index));   \n",
    "    }\n",
    "    return selected_jets;\n",
    "}\n",
    "\n",
    "ROOT::VecOps::RVec<float> jets_p4_pt(const ROOT::VecOps::RVec<LorentzVectorE>& jets_p4)\n",
    "{   \n",
    "    ROOT::VecOps::RVec<float> pt(jets_p4.size());\n",
    "    for(size_t jet_index = 0; jet_index < jets_p4.size(); ++jet_index)\n",
    "        pt.push_back(jets_p4.at(jet_index).pt());\n",
    "    return pt;\n",
    "}\n",
    "\n",
    "ROOT::VecOps::RVec<float> jets_p4_eta(const ROOT::VecOps::RVec<LorentzVectorE>& jets_p4)\n",
    "{   \n",
    "    ROOT::VecOps::RVec<float> eta(jets_p4.size());\n",
    "    for(size_t jet_index = 0; jet_index < jets_p4.size(); ++jet_index)\n",
    "        eta.push_back(jets_p4.at(jet_index).eta());\n",
    "    return eta;\n",
    "}\n",
    "\n",
    "\n",
    "ROOT::VecOps::RVec<float> jets_p4_E(const ROOT::VecOps::RVec<LorentzVectorE>& jets_p4)\n",
    "{   \n",
    "    ROOT::VecOps::RVec<float> E(jets_p4.size());\n",
    "    for(size_t jet_index = 0; jet_index < jets_p4.size(); ++jet_index)\n",
    "        E.push_back(jets_p4.at(jet_index).E());\n",
    "    return E;\n",
    "}\n",
    "\n",
    "ROOT::VecOps::RVec<float> jets_p4_M(const ROOT::VecOps::RVec<LorentzVectorE>& jets_p4)\n",
    "{   \n",
    "    ROOT::VecOps::RVec<float> M(jets_p4.size());\n",
    "    for(size_t jet_index = 0; jet_index < jets_p4.size(); ++jet_index)\n",
    "        M.push_back(jets_p4.at(jet_index).M());\n",
    "    return M;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "vector<size_t>& good_jets_indexes(const ROOT::VecOps::RVec<LorentzVectorE>& jets_p4)\n",
    "{    \n",
    "    static vector<size_t> good_jets_index;\n",
    "    for(size_t jet_index = 0; jet_index < jets_p4.size(); ++jet_index){\n",
    "        if(jets_p4.at(jet_index).pt() > 20 && abs(jets_p4.at(jet_index).eta()) < 2.4)\n",
    "            good_jets_index.push_back(jet_index);   \n",
    "    }\n",
    "    return good_jets_index;\n",
    "\n",
    "}\n",
    "\n",
    "ROOT::VecOps::RVec<float> jets_deepFlavour (const ROOT::VecOps::RVec<LorentzVectorE>& jets_p4, const ROOT::VecOps::RVec<float>& jets_deepFlavour_b,\n",
    "                                const ROOT::VecOps::RVec<float>& jets_deepFlavour_bb, const ROOT::VecOps::RVec<float>& jets_deepFlavour_lepb)\n",
    "{\n",
    "    vector<float> jets_deepFlavour;\n",
    "    for(size_t jet_index = 0; jet_index < jets_p4.size(); ++jet_index){\n",
    "        if(jets_p4.at(jet_index).pt() > 20 && abs(jets_p4.at(jet_index).eta()) < 2.4){   \n",
    "            float jet_deepFlavour = jets_deepFlavour_b.at(jet_index) + jets_deepFlavour_bb.at(jet_index)\n",
    "            + jets_deepFlavour_lepb.at(jet_index);\n",
    "            jets_deepFlavour.push_back(jet_deepFlavour);\n",
    "        }\n",
    "    }\n",
    "    return jets_deepFlavour;\n",
    "}\n",
    "\n",
    "LorentzVectorM getHTTp4(const ROOT::VecOps::RVec<LorentzVectorM>& lep_p4,\n",
    "                        const ROOT::VecOps::RVec<int>& lep_genTauIndex)\n",
    "{\n",
    "    size_t n_tau = 0;\n",
    "    LorentzVector htt(0, 0, 0, 0);\n",
    "    for(size_t n = 0; n < lep_p4.size(); ++n) {\n",
    "        if(lep_genTauIndex.at(n) >= 0) {\n",
    "            htt += lep_p4.at(n);\n",
    "            n_tau++;\n",
    "        }\n",
    "    }\n",
    "    if(n_tau != 2)\n",
    "        throw std::runtime_error(\"too few taus\");\n",
    "    return LorentzVectorM(htt);\n",
    "}\n",
    "\n",
    "ROOT::VecOps::RVec<float> httDeltaPhi(const LorentzVectorM& htt_p4, const ROOT::VecOps::RVec<LorentzVectorE>& jets_p4)\n",
    "{\n",
    "    ROOT::VecOps::RVec<float> dphi(jets_p4.size());\n",
    "    for(size_t n = 0; n < jets_p4.size(); ++n) {\n",
    "        dphi.at(n) = ROOT::Math::VectorUtil::DeltaPhi(htt_p4, jets_p4.at(n));\n",
    "    }\n",
    "    return dphi;\n",
    "}\n",
    "\n",
    "ROOT::VecOps::RVec<float> httDeltaEta(const LorentzVectorM& htt_p4, const ROOT::VecOps::RVec<LorentzVectorE>& jets_p4)\n",
    "{\n",
    "    ROOT::VecOps::RVec<float> deta(jets_p4.size());\n",
    "    for(size_t n = 0; n < jets_p4.size(); ++n) {\n",
    "        deta.at(n) = htt_p4.eta() - jets_p4.at(n).eta();\n",
    "    }\n",
    "    return deta;\n",
    "}\n",
    "\n",
    "float httMetDeltaPhi(const LorentzVectorM& htt_p4, \n",
    "                     const LorentzVectorM& met_p4)\n",
    "{\n",
    "    float dphi = ROOT::Math::VectorUtil::DeltaPhi(htt_p4, met_p4);    \n",
    "    return dphi;\n",
    "}\n",
    "\n",
    "float met_pt(LorentzVectorM& met_p4)\n",
    "{\n",
    "    return met_p4.pt();\n",
    "}\n",
    "\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/dido/all_samples/GluGluToHHTo2B2Tau_node_SM_eTau_2017_ggHH_NonRes.root'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = '/data/dido/all_samples/GluGluToHHTo2B2Tau_node_SM_eTau_2017_ggHH_NonRes.root'\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauTau_file = file_name\n",
    "df = ROOT.ROOT.RDataFrame('all_events', file_name)\n",
    "\n",
    "df = df.Define('jets_p4_good'  , 'jets_p4_good(jets_p4)') \\\n",
    "       .Define('jets_p4_pt' , 'jets_p4_pt(jets_p4_good)') \\\n",
    "       .Define('jets_p4_eta' , 'jets_p4_eta(jets_p4_good)') \\\n",
    "       .Define('jets_p4_E'   , 'jets_p4_E(jets_p4_good)') \\\n",
    "       .Define('jets_p4_M'   , 'jets_p4_M(jets_p4_good)') \\\n",
    "       .Define('htt_p4'      , 'getHTTp4(lep_p4, lep_genTauIndex)') \\\n",
    "       .Define('jets_htt_dphi', 'httDeltaPhi(htt_p4, jets_p4_good)') \\\n",
    "       .Define('jets_htt_deta', 'httDeltaEta(htt_p4, jets_p4_good)') \\\n",
    "       .Define('jets_htt_met_dphi', 'httMetDeltaPhi(htt_p4, pfMET_p4)') \\\n",
    "       .Define('met_pt', 'met_pt(pfMET_p4)') \\\n",
    "       .Define('jets_deepFlavour', 'jets_deepFlavour(jets_p4, jets_deepFlavour_b,  jets_deepFlavour_bb, jets_deepFlavour_lepb)') \\\n",
    "       .Define('n_jets', 'jets_p4_good.size()')\n",
    "#        .Define('good_jets_indexes', 'good_jets_indexes(jets_p4)') \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.Filter('evt % 2 == 0')\n",
    "df_test = df.Filter('evt % 2 == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_columns = [\n",
    "    'sample_type', 'spin', 'mass_point', 'node', 'sample_year', 'channelId', 'jets_htt_met_dphi', 'met_pt', 'n_jets'\n",
    "]\n",
    "\n",
    "\n",
    "jet_columns = [ 'jets_p4_pt', 'jets_p4_eta', 'jets_p4_E', 'jets_p4_M', 'jets_htt_deta', 'jets_deepFlavour', \n",
    "               'jets_htt_dphi', 'jets_genJetIndex'\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateInputs(raw_data):\n",
    "    max_jet = int(raw_data['n_jets'].max())\n",
    "    n_vars = 11 \n",
    "    n_truth = 6\n",
    "    evt_var_pos_shift = 1\n",
    "    jet_var_pos_shift = evt_var_pos_shift + len(evt_columns)\n",
    "    n_evt = len(raw_data['n_jets'])\n",
    "    data = np.zeros((n_evt, max_jet, n_truth + n_vars + 1), dtype=np.float32)\n",
    "    gen_truth = np.zeros((n_evt, max_jet), dtype=np.float32)\n",
    "    for evt_idx in range(n_evt):\n",
    "        \n",
    "        for col_id in range(len(evt_columns)):\n",
    "            data[evt_idx, :, col_id + evt_var_pos_shift] = raw_data[evt_columns[col_id]][evt_idx]\n",
    "\n",
    "        for jet_idx in range(int(raw_data['n_jets'][evt_idx])):\n",
    "            for col_id in range(len(jet_columns) - 1):\n",
    "                data[evt_idx, jet_idx, col_id + jet_var_pos_shift] = raw_data[jet_columns[col_id]][evt_idx][jet_idx]\n",
    "            data[evt_idx, jet_idx, len(jet_columns) + jet_var_pos_shift -1] = raw_data[jet_columns[len(jet_columns) -1]][evt_idx][jet_idx] >= 0\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_vars = 11 \n",
    "n_truth = 6\n",
    "parity = 0 \n",
    "train_data = None\n",
    "test_data = None\n",
    "\n",
    "data_raw_train = df_train.AsNumpy(columns=jet_columns+evt_columns)\n",
    "data_raw_test = df_test.AsNumpy(columns=jet_columns+evt_columns)\n",
    "\n",
    "train_data_ch = CreateInputs(data_raw_train)\n",
    "test_data_ch = CreateInputs(data_raw_test)\n",
    "\n",
    "if train_data is not None :\n",
    "    train_data = np.append(train_data, train_data_ch)\n",
    "else :\n",
    "    train_data = train_data_ch\n",
    "    \n",
    "if test_data is not None :\n",
    "    test_data = np.append(test_data, test_data_ch)\n",
    "else :\n",
    "    test_data = test_data_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_acc(y_true, y_pred):\n",
    "    pred_sorted = tf.argsort(y_pred, axis=1, direction='DESCENDING')\n",
    "    #return pred_sorted[:, 0]\n",
    "    n_evt = tf.shape(y_true)[0]\n",
    "    evt_id = tf.range(n_evt)\n",
    "    #index_0 = tf.transpose(tf.stack([evt_id, pred_sorted[:, 0]]))\n",
    "    #index_1 = tf.transpose(tf.stack([evt_id, pred_sorted[:, 1]]))\n",
    "    index_0 = tf.transpose(tf.stack([evt_id, tf.reshape(pred_sorted[:, 0], shape=(n_evt,))]))\n",
    "    index_1 = tf.transpose(tf.stack([evt_id, tf.reshape(pred_sorted[:, 1], shape=(n_evt,))]))\n",
    "    matches_0 = tf.gather_nd(y_true, index_0)\n",
    "    matches_1 = tf.gather_nd(y_true, index_1)\n",
    "    valid = tf.cast(tf.equal(matches_0 + matches_1, 2), tf.float32)\n",
    "    n_valid = tf.reduce_sum(valid)\n",
    "    return n_valid / tf.cast(n_evt, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_prod(point, year):\n",
    "    index = []\n",
    "    for node in range(0, len(point)) :\n",
    "        index.append((train_data[:, 0, 1] == 7) & (train_data[:, 0, 4] == point[node]) & (train_data[:, 0, 5] == year))\n",
    "    print(len(index))\n",
    "\n",
    "    acc = []\n",
    "    for idx in range(0, len(index)):\n",
    "        pred = train_data[index[idx], : , n_truth+n_vars:]\n",
    "        y_pred = train_data[index[idx], :, 15]\n",
    "        x = sel_acc(pred, y_pred).numpy()\n",
    "        acc.append(x)\n",
    "    print(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_2016 = acc_prod(nodes_values, 2016)\n",
    "acc_2017 = acc_prod(nodes_values, 2017)\n",
    "acc_2018 = acc_prod(nodes_values, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for node in range(len(nodes_label)) :\n",
    "ax = plt.gca()\n",
    "\n",
    "df_2017 = pd.DataFrame(data=acc_2017)\n",
    "df_2018 = pd.DataFrame(data=acc_2018)\n",
    "    \n",
    "df_2017.plot(kind='line', label='label',ax=ax)\n",
    "df_2017.plot(kind='line',ax=ax, color='red', label='label')\n",
    "plt.gca().legend(('2017','2016'))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HHModel(Model):\n",
    "    def __init__(self):\n",
    "        super(HHModel, self).__init__()\n",
    "        self.lstm_1 = LSTM(8, return_sequences=True)\n",
    "        self.dropout_1 = Dropout(0.2)\n",
    "        self.concat_1 = Concatenate()\n",
    "        self.lstm_2 = LSTM(8, return_sequences=True)\n",
    "        self.dropout_2 = Dropout(0.2)\n",
    "        self.dense_1 = TimeDistributed(Dense(10, activation=\"sigmoid\"))\n",
    "        self.dense_2 = TimeDistributed(Dense(1, activation=\"sigmoid\"))\n",
    "  \n",
    "    def call(self, inputs):\n",
    "        x = self.lstm_1(inputs)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.concat_1([inputs, x])\n",
    "        x = self.lstm_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        input_shape = tf.shape(inputs)\n",
    "        return tf.reshape(x, shape=(input_shape[0], input_shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HHModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.call(X_train[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once your model looks good, configure its learning process with .compile():\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[sel_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(X_train.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_red = Y_train[:,:,0]\n",
    "Y_train_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train[:,:,0], validation_split=0.2, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(Y_test[:,:,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate it and print the results:\n",
    "# test_loss, test_acc = model.evaluate(X_test, Y_test[:,:,0], batch_size=120)\n",
    "\n",
    "# print('Test accuracy:', test_acc)\n",
    "# print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
